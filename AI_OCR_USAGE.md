# AI OCR Integration in OcrScanModal

## √úberblick

Die `OcrScanModal` Komponente wurde erfolgreich um KI-gest√ºtzte OCR-Funktionalit√§t erweitert. Benutzer k√∂nnen nun zwischen zwei OCR-Modi w√§hlen:

1. **Standard-OCR (Tesseract.js)** - Offline-f√§hig, datenschutzfreundlich
2. **KI-Scan (Google Gemini Vision)** - Strukturierte Erkennung mit AI √ºber Firebase Cloud Functions

## üîí Sicherheitsverbesserung: Cloud Functions

**WICHTIG**: Der Gemini API-Key wird jetzt sicher serverseitig in Firebase Cloud Functions gespeichert, nicht mehr im Frontend!

### Vorteile der Cloud Function-Implementierung

‚úÖ **Sicherheit**: API-Key ist nicht im Browser sichtbar  
‚úÖ **Kostenkontrolle**: Rate Limiting verhindert Missbrauch  
‚úÖ **Authentifizierung**: Nur eingeloggte Nutzer k√∂nnen AI OCR nutzen  
‚úÖ **Validierung**: Bildgr√∂√üe und -typ werden serverseitig gepr√ºft  

### Rate Limits

- **Authentifizierte Nutzer**: 20 Scans pro Tag
- **Gast-Nutzer (Anonymous Auth)**: 5 Scans pro Tag

## Setup und Konfiguration

### 1. Firebase Cloud Functions einrichten

```bash
# API-Key als Secret setzen
firebase functions:secrets:set GEMINI_API_KEY

# Oder √ºber Firebase Console:
# Firebase Console ‚Üí Functions ‚Üí Secrets ‚Üí Add secret
# Name: GEMINI_API_KEY
# Wert: [Dein Gemini API-Key]
```

### 2. Cloud Functions deployen

```bash
# Alle Functions deployen
firebase deploy --only functions

# Oder nur die scanRecipeWithAI Function
firebase deploy --only functions:scanRecipeWithAI
```

### 3. Gemini API-Key erhalten

1. Gehe zu [Google AI Studio](https://aistudio.google.com/)
2. Erstelle einen API-Key
3. Setze den Key als Firebase Secret (siehe Schritt 1)

### 4. Firestore-Regeln aktualisieren (falls n√∂tig)

Die Cloud Function ben√∂tigt Schreibzugriff auf die `aiScanLimits` Collection f√ºr Rate Limiting:

```javascript
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    // Andere Regeln...
    
    match /aiScanLimits/{document=**} {
      allow read, write: if request.auth != null;
    }
  }
}
```

## Neue Features

### 1. OCR-Modus-Auswahl

Im Upload-Schritt k√∂nnen Benutzer zwischen zwei Modi w√§hlen:

- **üìù Standard-OCR**: Verwendet Tesseract.js f√ºr einfache Texterkennung
- **ü§ñ KI-Scan (Gemini)**: Nutzt Google Gemini Vision API f√ºr strukturierte Rezepterkennung

Der KI-Scan Button ist:
- **Aktiviert**: Wenn ein Gemini API-Key konfiguriert ist
- **Deaktiviert**: Wenn kein API-Key vorhanden ist, mit Hinweistext

### 2. AI-Ergebnis-Vorschau

Nach einem erfolgreichen KI-Scan wird eine strukturierte Vorschau angezeigt:

- **Titel**: Gro√ü und prominent
- **Metadaten als Badges**:
  - üë• Portionen
  - ‚è±Ô∏è Zubereitungszeit/Kochzeit
  - üìä Schwierigkeitsgrad (1-5)
  - üåç Kulinarische Herkunft
  - üìÇ Kategorie

- **Zutaten**: Als Aufz√§hlungsliste
- **Zubereitungsschritte**: Als nummerierte Liste
- **Tags**: Visualisiert als farbige Badges (vegetarisch, vegan, etc.)

### 3. Flexible Bearbeitungsm√∂glichkeiten

Benutzer k√∂nnen:
1. **Direkt √ºbernehmen**: Das strukturierte Ergebnis direkt importieren
2. **Als Text bearbeiten**: Das Ergebnis in Text-Format konvertieren und manuell anpassen

### 4. Intelligente Fehlerbehandlung

- API-Fehler werden benutzerfreundlich angezeigt
- Bei Fehlern kann der Benutzer zum Standard-OCR wechseln
- Klare Hinweise bei fehlender API-Konfiguration

## Technische Details

### State Management

Neue State-Variablen:
- `ocrMode`: `'standard'` (default) oder `'ai'`
- `aiResult`: Strukturiertes Ergebnis von Gemini API

### Flow-√Ñnderungen

#### Standard-OCR Flow (unver√§ndert):
1. Upload/Kamera ‚Üí Scan ‚Üí Edit ‚Üí Import

#### KI-OCR Flow (neu):
1. Upload/Kamera ‚Üí Scan (KI-Modus w√§hlen) ‚Üí **AI-Result** ‚Üí Import
   - Optional: AI-Result ‚Üí Edit (als Text) ‚Üí Import

### API Integration

Die Integration nutzt die bestehende `aiOcrService.js`:

```javascript
import { recognizeRecipeWithAI, isAiOcrAvailable } from '../utils/aiOcrService';

// Pr√ºfen ob AI verf√ºgbar
const isAvailable = isAiOcrAvailable('gemini');

// AI OCR durchf√ºhren
const result = await recognizeRecipeWithAI(imageBase64, {
  language: 'de',
  provider: 'gemini',
  onProgress: (progress) => setScanProgress(progress)
});
```

### Datenstruktur

Das AI-Ergebnis hat folgende Struktur:

```javascript
{
  title: string,
  servings: number,
  prepTime: string,
  cookTime: string,
  difficulty: number (1-5),
  cuisine: string,
  category: string,
  tags: string[],
  ingredients: string[],
  steps: string[],
  notes: string
}
```

Dies wird beim Import in das Recipe-Format konvertiert:

```javascript
{
  title: aiResult.title,
  ingredients: aiResult.ingredients,
  steps: aiResult.steps,
  portionen: aiResult.servings,
  kochdauer: parseInt(aiResult.prepTime) || parseInt(aiResult.cookTime),
  kulinarik: [aiResult.cuisine],
  schwierigkeit: aiResult.difficulty,
  speisekategorie: aiResult.category
}
```

## Styling

### Neue CSS-Klassen

- `.ocr-mode-selector` - Container f√ºr Modus-Auswahl
- `.ocr-mode-tab` - Tab-Buttons (Standard/AI)
- `.ocr-mode-tab.active` - Aktiver Tab
- `.ocr-mode-tab.disabled` - Deaktivierter Tab
- `.ai-hint` - Hinweistexte
- `.ai-result-section` - Container f√ºr AI-Ergebnis
- `.ai-result-title` - Rezepttitel
- `.ai-result-meta` - Metadaten-Container
- `.ai-meta-badge` - Einzelne Metadaten-Badge
- `.ai-result-ingredients` - Zutatenliste
- `.ai-result-steps` - Zubereitungsschritte
- `.ai-result-tags` - Tag-Container
- `.ai-tag` - Einzelner Tag
- `.edit-text-button` - "Als Text bearbeiten" Button

Alle Styles sind konsistent mit den bestehenden Styles und vollst√§ndig responsive.

## Tests

### Neue Tests (6 zus√§tzliche Tests)

1. **AI OCR Modus-Selektor anzeigen**: Pr√ºft ob beide Tabs angezeigt werden
2. **Hinweis bei fehlender API**: Zeigt Hinweis wenn kein API-Key vorhanden
3. **AI OCR Verarbeitung**: Testet kompletten AI-Scan-Flow
4. **Direkter Import**: Pr√ºft Import der strukturierten Daten
5. **Text-Konvertierung**: Testet "Als Text bearbeiten" Funktion
6. **Fehlerbehandlung**: Pr√ºft graceful Error Handling

**Test-Ergebnisse**: Alle 25 Tests bestehen ‚úÖ

## Migration & Entwicklung

### Lokale Entwicklung mit Emulator

F√ºr lokale Tests mit Firebase Functions Emulator:

```bash
# Functions Emulator starten
cd functions
npm install
firebase emulators:start --only functions

# In einem anderen Terminal die App starten
npm start
```

Der Emulator l√§uft standardm√§√üig auf `http://localhost:5001`. Die Frontend-App wird automatisch die lokalen Functions verwenden.

### Kosten & Limits

- **Firebase Cloud Functions**: Gro√üz√ºgiger Free Tier (2M Invocations/Monat)
- **Gemini API**: Gro√üz√ºgiges kostenloses Kontingent ([Google AI Pricing](https://ai.google.dev/pricing))
- **Rate Limiting**: Schutz vor √ºberm√§√üiger Nutzung (20/Tag f√ºr User, 5/Tag f√ºr G√§ste)
- **Privacy**: Bilder werden sicher √ºber Firebase an Google gesendet
- **Geschwindigkeit**: 2-5 Sekunden pro Bild

**Hinweis**: API-Limits k√∂nnen sich √§ndern. Bitte pr√ºfen Sie die aktuelle Dokumentation.

## Fehlerbehandlung

Die Cloud Function gibt strukturierte Fehler zur√ºck:

- `unauthenticated`: Benutzer muss eingeloggt sein
- `resource-exhausted`: Rate Limit √ºberschritten
- `invalid-argument`: Ung√ºltige Bilddaten (zu gro√ü, falscher Typ)
- `failed-precondition`: API-Key nicht konfiguriert
- `internal`: Gemini API-Fehler

## Backward Compatibility

- ‚úÖ Alle bestehenden Tests bestehen weiterhin (23/23)
- ‚úÖ Standard-OCR funktioniert unver√§ndert
- ‚úÖ Keine Breaking Changes in der UI
- ‚úÖ KI-Feature ist immer verf√ºgbar (wenn Cloud Function deployed ist)
- ‚úÖ Alte REACT_APP_GEMINI_API_KEY wird ignoriert (deprecated)

## N√§chste Schritte

M√∂gliche Erweiterungen:
- [ ] Support f√ºr OpenAI Vision API (Vorbereitung bereits in `aiOcrService.js`)
- [ ] Batch-Processing mehrerer Rezepte
- [ ] Verbesserung der AI-Prompts f√ºr bessere Erkennung
- [ ] Admin-Dashboard f√ºr Rate Limit Monitoring
- [ ] Lokale KI-Modelle f√ºr Offline-Nutzung
